{
  "artifacts": [],
  "command": "my_main",
  "experiment": {
    "base_dir": "/home/kamil/Desktop/Zaidi/MISA work/try again/Multi-Agent-Communication-Considering-Representation-Learning/src",
    "dependencies": [
      "numpy==1.26.2",
      "PyYAML==6.0.1",
      "sacred==0.8.5",
      "torch==2.1.1"
    ],
    "mainfile": "main.py",
    "name": "pymarl",
    "repositories": [
      {
        "commit": "bef503decff17e7005b1b760f2d9b7c8691b9fc4",
        "dirty": true,
        "url": "https://github.com/chenf-ai/Multi-Agent-Communication-Considering-Representation-Learning"
      },
      {
        "commit": "bef503decff17e7005b1b760f2d9b7c8691b9fc4",
        "dirty": true,
        "url": "https://github.com/chenf-ai/Multi-Agent-Communication-Considering-Representation-Learning"
      },
      {
        "commit": "bef503decff17e7005b1b760f2d9b7c8691b9fc4",
        "dirty": true,
        "url": "https://github.com/chenf-ai/Multi-Agent-Communication-Considering-Representation-Learning"
      },
      {
        "commit": "bef503decff17e7005b1b760f2d9b7c8691b9fc4",
        "dirty": true,
        "url": "https://github.com/chenf-ai/Multi-Agent-Communication-Considering-Representation-Learning"
      }
    ],
    "sources": [
      [
        "main.py",
        "_sources/main_3c56889e6bd6bf4dabb228d4dbfa334d.py"
      ],
      [
        "msra_run.py",
        "_sources/msra_run_38297b6b7973b90ec2fc159b92f9971f.py"
      ],
      [
        "run.py",
        "_sources/run_0a98792e111bf864becce80676f535b9.py"
      ],
      [
        "utils/logging.py",
        "_sources/logging_8309e899ab76a4e610428ba7ee8d8acb.py"
      ]
    ]
  },
  "fail_trace": [
    "Traceback (most recent call last):\n",
    "  File \"/home/kamil/Desktop/Zaidi/MISA work/try again/Multi-Agent-Communication-Considering-Representation-Learning/venv/lib/python3.10/site-packages/sacred/config/captured_function.py\", line 42, in captured_function\n    result = wrapped(*args, **kwargs)\n",
    "  File \"/home/kamil/Desktop/Zaidi/MISA work/try again/Multi-Agent-Communication-Considering-Representation-Learning/src/main.py\", line 42, in my_main\n    run(_run, config, _log)\n",
    "  File \"/home/kamil/Desktop/Zaidi/MISA work/try again/Multi-Agent-Communication-Considering-Representation-Learning/src/run.py\", line 118, in run\n    run_sequential(args=args, logger=logger)\n",
    "  File \"/home/kamil/Desktop/Zaidi/MISA work/try again/Multi-Agent-Communication-Considering-Representation-Learning/src/run.py\", line 250, in run_sequential\n    episode_batch = runner.run(test_mode=False)\n",
    "  File \"/home/kamil/Desktop/Zaidi/MISA work/try again/Multi-Agent-Communication-Considering-Representation-Learning/src/runners/episode_runner.py\", line 49, in run\n    self.reset()\n",
    "  File \"/home/kamil/Desktop/Zaidi/MISA work/try again/Multi-Agent-Communication-Considering-Representation-Learning/src/runners/episode_runner.py\", line 45, in reset\n    self.env.reset()\n",
    "  File \"/home/kamil/Desktop/Zaidi/MISA work/try again/Multi-Agent-Communication-Considering-Representation-Learning/src/envs/__init__.py\", line 322, in reset\n    self._obs, self._state = self._env.reset()\n",
    "  File \"/home/kamil/Desktop/Zaidi/MISA work/try again/Multi-Agent-Communication-Considering-Representation-Learning/src/envs/lbf_envs/lbf_env.py\", line 1012, in reset\n    self.spawn_players(self.max_player_level)\n",
    "  File \"/home/kamil/Desktop/Zaidi/MISA work/try again/Multi-Agent-Communication-Considering-Representation-Learning/src/envs/lbf_envs/lbf_env.py\", line 834, in spawn_players\n    self.np_random.integers(1, max_player_level),\n",
    "AttributeError: 'numpy.random._generator.Generator' object has no attribute 'randint'\n"
  ],
  "heartbeat": "2023-12-10T18:43:26.170069",
  "host": {
    "ENV": {},
    "cpu": "Intel(R) Core(TM) i7-7700HQ CPU @ 2.80GHz",
    "gpus": {
      "driver_version": "525.147.05",
      "gpus": [
        {
          "model": "NVIDIA GeForce GTX 1060",
          "persistence_mode": false,
          "total_memory": 6144
        }
      ]
    },
    "hostname": "Koky-Hero",
    "os": [
      "Linux",
      "Linux-6.2.0-37-generic-x86_64-with-glibc2.35"
    ],
    "python_version": "3.10.12"
  },
  "meta": {
    "command": "my_main",
    "config_updates": {
      "env_args": {
        "field_size": 11,
        "force_coop": false,
        "max_food": 4,
        "players": 6,
        "sight": 1
      }
    },
    "named_configs": [],
    "options": {
      "--beat-interval": null,
      "--capture": null,
      "--comment": null,
      "--debug": false,
      "--enforce_clean": false,
      "--file_storage": null,
      "--force": false,
      "--help": false,
      "--id": null,
      "--loglevel": null,
      "--mongo_db": null,
      "--name": null,
      "--pdb": false,
      "--print-config": false,
      "--priority": null,
      "--queue": false,
      "--s3": null,
      "--sql": null,
      "--tiny_db": null,
      "--unobserved": false,
      "COMMAND": null,
      "UPDATE": [
        "env_args.sight=1",
        "env_args.players=6",
        "env_args.field_size=11",
        "env_args.max_food=4",
        "env_args.force_coop=False"
      ],
      "help": false,
      "with": true
    }
  },
  "resources": [],
  "result": null,
  "start_time": "2023-12-10T18:43:24.573833",
  "status": "FAILED",
  "stop_time": "2023-12-10T18:43:26.171087"
}